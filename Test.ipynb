{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiger\\anaconda3\\envs\\kakao\\lib\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import gluonnlp as nlp\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#GPU 사용\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, bert_tokenizer, args):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=args.max_len, pad=args.pad, pair=args.pair)\n",
    "\n",
    "        self.sentences = [transform([i]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert, \n",
    "                 hidden_size=768, \n",
    "                 num_classes=7,\n",
    "                 dr_rate=0.5,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if self.dr_rate:\n",
    "            self.dropout = nn.Dropout(p=self.dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_test, args):\n",
    "    test_dataloader = DataLoader(data_test, \n",
    "                                 batch_size=args.batch_size) #, num_workers=args.num_workers) \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    current_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for token_ids, valid_length, segment_ids in test_dataloader:\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "\n",
    "            current_preds.extend(predicted)\n",
    "            \n",
    "    return current_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClassifier(bertmodel).to(device)\n",
    "model.load_state_dict(torch.load('./weight/bert_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "# ====== Random seed Initialization ====== #\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# Setting parameters\n",
    "args.sent_idx = 0\n",
    "args.label_idx = 1\n",
    "args.max_len = 64\n",
    "args.pad = True\n",
    "args.pair = False\n",
    "\n",
    "args.num_workers = 4\n",
    "args.batch_size = 64\n",
    "\n",
    "args.warmup_ratio = 0.1\n",
    "args.num_epochs = 20\n",
    "\n",
    "args.max_grad_norm = 1\n",
    "\n",
    "args.log_interval = 100\n",
    "\n",
    "args.learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ['창가로 옮겼더니 너무 춥다..',\n",
    " '아직도 창밖은 별빛으로 가득해 !!',\n",
    " '귀여운건 거꾸로 해도 귀엽지',\n",
    " '긴 문장에 대한 효용성은 아무리 강조해도 지나치지 않지만 그것이 어떠한 감정을 설명한 다는 것은 무척이나 빈약한 근거 위에 쌓아올린 논리라고 생각해',\n",
    " '오오오오오오',\n",
    " '이럴수가',\n",
    " '우오오오오오오오오오오와',\n",
    " '배고픈데 치과가기 싫어',\n",
    " '크리스마스트리만들었다!',\n",
    " '이거 사이코패스한테 팔자',\n",
    " '오늘 학원등록할게요',\n",
    " '아티제 화이트롤이랑 아이스 아메리카노를 먹으러 갈거예요',\n",
    " '크리스마스캐롤을 틀어놓고 나는 샤워를 합니다',\n",
    " '짜장면에 탕수육 소스는 부을까요 말까요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = input('문장을 입력하세요 :')\n",
    "# data_list.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = BERTDataset(data_list, tok, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = test(model, data_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(pred_list):\n",
    "    a = e.to('cpu').numpy()\n",
    "    if a == 0:\n",
    "        a = '공포'\n",
    "    elif a == 1:\n",
    "        a = '놀람'\n",
    "    elif a == 2:\n",
    "        a = '분노'\n",
    "    elif a == 3:\n",
    "        a = '슬픔'\n",
    "    elif a == 4:\n",
    "        a = '중립'\n",
    "    elif a == 5:\n",
    "        a = '행복'\n",
    "    elif a == 6:\n",
    "        a = '혐오'\n",
    "    \n",
    "    pred_list[i] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Sentrnce'] = data_list\n",
    "df['Emotion'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentrnce</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>창가로 옮겼더니 너무 춥다..</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아직도 창밖은 별빛으로 가득해 !!</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>귀여운건 거꾸로 해도 귀엽지</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>긴 문장에 대한 효용성은 아무리 강조해도 지나치지 않지만 그것이 어떠한 감정을 설명...</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오오오오오오</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>이럴수가</td>\n",
       "      <td>놀람</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>우오오오오오오오오오오와</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>배고픈데 치과가기 싫어</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>크리스마스트리만들었다!</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>이거 사이코패스한테 팔자</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>오늘 학원등록할게요</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>아티제 화이트롤이랑 아이스 아메리카노를 먹으러 갈거예요</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>크리스마스캐롤을 틀어놓고 나는 샤워를 합니다</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>짜장면에 탕수육 소스는 부을까요 말까요</td>\n",
       "      <td>공포</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentrnce Emotion\n",
       "0                                    창가로 옮겼더니 너무 춥다..      슬픔\n",
       "1                                 아직도 창밖은 별빛으로 가득해 !!      행복\n",
       "2                                     귀여운건 거꾸로 해도 귀엽지      행복\n",
       "3   긴 문장에 대한 효용성은 아무리 강조해도 지나치지 않지만 그것이 어떠한 감정을 설명...      중립\n",
       "4                                              오오오오오오      중립\n",
       "5                                                이럴수가      놀람\n",
       "6                                        우오오오오오오오오오오와      행복\n",
       "7                                        배고픈데 치과가기 싫어      슬픔\n",
       "8                                        크리스마스트리만들었다!      행복\n",
       "9                                       이거 사이코패스한테 팔자      분노\n",
       "10                                         오늘 학원등록할게요      중립\n",
       "11                     아티제 화이트롤이랑 아이스 아메리카노를 먹으러 갈거예요      중립\n",
       "12                           크리스마스캐롤을 틀어놓고 나는 샤워를 합니다      중립\n",
       "13                              짜장면에 탕수육 소스는 부을까요 말까요      공포"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47733dae5d843d2eb72fe4c3b10f7ff7bdbfd472b67086abca35bd19fbf674b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('kakao': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
